{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14004257,"sourceType":"datasetVersion","datasetId":8922832}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3a37df7d","cell_type":"markdown","source":"# CNN-LSTM with Medically Realistic Augmentation\n\nSelf-contained notebook for Kaggle: loads the clean Alzheimer dataset, applies conservative augmentation (±15° rotations, no flips), trains an enhanced CNN+LSTM, and reports metrics/saves the model.\n\n> Set `DATA_ROOT` below for Kaggle (`/kaggle/input/alzheimer-clean-dataset/Alzheimer_Clean_Dataset`) or local.","metadata":{}},{"id":"adcef86f","cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n)\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.layers import (\n    Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Reshape, LSTM\n)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# GPU config (safe defaults for Kaggle/local)\nprint(\"GPU Configuration:\")\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    print(f\"  Using {len(gpus)} GPU(s)\")\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"  GPU memory growth enabled\")\n    except RuntimeError:\n        print(\"  GPU already initialized; memory growth skipped\")\nelse:\n    print(\"  No GPU detected; using CPU\")\n\nprint(f\"TensorFlow version: {tf.__version__}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:13:19.288321Z","iopub.execute_input":"2025-12-10T12:13:19.288642Z","iopub.status.idle":"2025-12-10T12:13:37.835134Z","shell.execute_reply.started":"2025-12-10T12:13:19.288615Z","shell.execute_reply":"2025-12-10T12:13:37.834332Z"}},"outputs":[{"name":"stderr","text":"2025-12-10 12:13:23.776095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765368803.964751      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765368804.014031      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"GPU Configuration:\n  Using 1 GPU(s)\n  GPU memory growth enabled\nTensorFlow version: 2.18.0\n","output_type":"stream"}],"execution_count":1},{"id":"2dd6feca","cell_type":"code","source":"# DATA PATH: set for Kaggle or local\n# Kaggle: DATA_ROOT = \"/kaggle/input/alzheimer-clean-dataset/Alzheimer_Clean_Dataset\"\n# Local:  DATA_ROOT = r\"d:\\\\ABDULLAH UNI\\\\Semester 7\\\\DL\\\\Classification-of-Alzheimer-s-disease-MRI-data-using-Deep-Learning\\\\Alzheimer_Clean_Dataset\"\nDATA_ROOT = \"/kaggle/input/alzheimer-clean-dataset/Alzheimer_Clean_Dataset\"\n\n# Label mapping (binary collapse)\nLABEL_MAP = {\n    \"NonDemented\": \"NonDemented\",\n    \"VeryMildDemented\": \"Demented\",\n    \"MildDemented\": \"Demented\",\n    \"ModerateDemented\": \"Demented\"\n}\n\nassert os.path.exists(DATA_ROOT), f\"DATA_ROOT not found: {DATA_ROOT}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:13:37.837196Z","iopub.execute_input":"2025-12-10T12:13:37.837661Z","iopub.status.idle":"2025-12-10T12:13:37.843809Z","shell.execute_reply.started":"2025-12-10T12:13:37.837642Z","shell.execute_reply":"2025-12-10T12:13:37.843103Z"}},"outputs":[],"execution_count":2},{"id":"14881251","cell_type":"code","source":"# Helpers: load dataset metadata with label mapping\n\ndef create_dataframe(split_dir):\n    rows = []\n    for class_name in os.listdir(split_dir):\n        class_path = os.path.join(split_dir, class_name)\n        if os.path.isdir(class_path):\n            mapped_label = LABEL_MAP.get(class_name, class_name)\n            for f in os.listdir(class_path):\n                if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    rows.append({\n                        'filename': os.path.join(class_path, f),\n                        'label': mapped_label\n                    })\n    return pd.DataFrame(rows)\n\ntrain_df = create_dataframe(os.path.join(DATA_ROOT, 'train'))\ntest_df = create_dataframe(os.path.join(DATA_ROOT, 'test'))\n\nprint(\"Train size:\", len(train_df))\nprint(train_df['label'].value_counts())\nprint(\"\\nTest size:\", len(test_df))\nprint(test_df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:13:37.844816Z","iopub.execute_input":"2025-12-10T12:13:37.845049Z","iopub.status.idle":"2025-12-10T12:13:38.074240Z","shell.execute_reply.started":"2025-12-10T12:13:37.845022Z","shell.execute_reply":"2025-12-10T12:13:38.073656Z"}},"outputs":[{"name":"stdout","text":"Train size: 5120\nlabel\nDemented       2560\nNonDemented    2560\nName: count, dtype: int64\n\nTest size: 1280\nlabel\nDemented       640\nNonDemented    640\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"id":"29e69749","cell_type":"code","source":"# Realistic augmentation generators (from improved-methodology)\n\ndef create_realistic_augmentation_generator():\n    return ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=15,\n        horizontal_flip=False,\n        vertical_flip=False,\n        zoom_range=0.1,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        brightness_range=[0.9, 1.1],\n        fill_mode='nearest'\n    )\n\ndef create_no_augmentation_generator():\n    return ImageDataGenerator(rescale=1./255)\n\ndef create_data_generators(input_size=(128, 128), batch_size=8):\n    classes = ['NonDemented', 'Demented']\n    train_datagen = create_realistic_augmentation_generator()\n    val_datagen = create_no_augmentation_generator()\n    train_gen = train_datagen.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='filename',\n        y_col='label',\n        target_size=input_size,\n        batch_size=batch_size,\n        class_mode='binary',\n        classes=classes,\n        color_mode='rgb',\n        shuffle=True,\n        seed=SEED\n    )\n    val_gen = val_datagen.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='filename',\n        y_col='label',\n        target_size=input_size,\n        batch_size=batch_size,\n        class_mode='binary',\n        classes=classes,\n        color_mode='rgb',\n        shuffle=False\n    )\n    return train_gen, val_gen\n\ntrain_gen, val_gen = create_data_generators(batch_size=8)\nprint(\"Generators ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:13:38.074978Z","iopub.execute_input":"2025-12-10T12:13:38.075657Z","iopub.status.idle":"2025-12-10T12:13:55.236480Z","shell.execute_reply.started":"2025-12-10T12:13:38.075628Z","shell.execute_reply":"2025-12-10T12:13:55.235815Z"}},"outputs":[{"name":"stdout","text":"Found 5120 validated image filenames belonging to 2 classes.\nFound 1280 validated image filenames belonging to 2 classes.\nGenerators ready.\n","output_type":"stream"}],"execution_count":4},{"id":"70ec8b70","cell_type":"code","source":"# Model: CNN-LSTM (simpler + stronger regularization for overfit control)\n\nfrom tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.regularizers import l2\n\n\ndef build_cnn_lstm_model(input_size=(128, 128)):\n    model = models.Sequential(name=\"CNN_LSTM_Realistic_Aug_Aligned\")\n    model.add(Input(shape=(*input_size, 3)))\n    # Conv Block 1\n    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    # Conv Block 2\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    # Conv Block 3\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.35))\n    # Conv Block 4\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.4))\n    # Reshape for LSTM bridge\n    model.add(Reshape((8*8, 256)))\n    model.add(TimeDistributed(Dense(128, activation='relu', kernel_regularizer=l2(1e-4))))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.35))\n    # Single LSTM (smaller)\n    model.add(LSTM(64, dropout=0.4, recurrent_dropout=0.4, kernel_regularizer=l2(1e-4)))\n    model.add(Dropout(0.45))\n    # Classifier head (compact): 128 -> 64 -> 2\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(1e-3)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(64, activation='relu', kernel_regularizer=l2(1e-3)))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='softmax'))\n    # Use standard sparse categorical crossentropy (label smoothing unavailable in this TF version)\n    model.compile(optimizer=Adam(learning_rate=0.0003, beta_1=0.9, beta_2=0.999),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\nmodel = build_cnn_lstm_model()\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:13:55.237241Z","iopub.execute_input":"2025-12-10T12:13:55.237476Z","iopub.status.idle":"2025-12-10T12:13:57.085639Z","shell.execute_reply.started":"2025-12-10T12:13:55.237451Z","shell.execute_reply":"2025-12-10T12:13:57.084925Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1765368835.359907      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"CNN_LSTM_Realistic_Aug_Aligned\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_LSTM_Realistic_Aug_Aligned\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m32,896\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m685,026\u001b[0m (2.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">685,026</span> (2.61 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m683,106\u001b[0m (2.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">683,106</span> (2.61 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"id":"b5f51f21","cell_type":"code","source":"print(\"=\"*80)\nprint(\"STEP 6: TRAINING WITH DYNAMIC REALISTIC AUGMENTATION\")\nprint(\"=\"*80)\n\n# IMPROVED Callbacks for better training\ncallbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',  # Monitor accuracy instead of loss\n        patience=20,  # More patience to allow convergence\n        restore_best_weights=True,\n        verbose=1,\n        mode='max'\n    ),\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,  # Moderate LR reduction (less aggressive)\n        patience=10,  # Wait longer before reducing\n        min_lr=1e-6,  # Higher minimum LR\n        verbose=1,\n        mode='min'\n    )\n]\n\nprint(\"\\n Training Configuration:\")\nprint(\"    Epochs: 150 (with early stopping)\")\nprint(\"    Batch size: 64 (increased for GPU efficiency)\")\nprint(\"    Optimizer: Adam (lr=0.001) - Original working config\")\nprint(\"    Augmentation: DYNAMIC (new transforms each epoch)\")\nprint(\"    Expected accuracy: ~85%+ (as achieved before)\")\nprint(\"\\n Starting training...\\n\")\n\n# Train\nstart_time = time.time()\n\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=150,  # More epochs\n    callbacks=callbacks,\n    verbose=1\n)\n\ntraining_time = (time.time() - start_time) / 60\n\nprint(f\"\\n Training complete!\")\nprint(f\"   Time: {training_time:.2f} minutes\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:13:57.086444Z","iopub.execute_input":"2025-12-10T12:13:57.086665Z","iopub.status.idle":"2025-12-10T17:24:06.325930Z","shell.execute_reply.started":"2025-12-10T12:13:57.086638Z","shell.execute_reply":"2025-12-10T17:24:06.325275Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTEP 6: TRAINING WITH DYNAMIC REALISTIC AUGMENTATION\n================================================================================\n\n Training Configuration:\n    Epochs: 150 (with early stopping)\n    Batch size: 64 (increased for GPU efficiency)\n    Optimizer: Adam (lr=0.001) - Original working config\n    Augmentation: DYNAMIC (new transforms each epoch)\n    Expected accuracy: ~85%+ (as achieved before)\n\n Starting training...\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/150\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1765368847.454199      48 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/CNN_LSTM_Realistic_Aug_Aligned_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nI0000 00:00:1765368848.862625     108 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 199ms/step - accuracy: 0.4932 - loss: 1.5350 - val_accuracy: 0.5000 - val_loss: 0.9623 - learning_rate: 3.0000e-04\nEpoch 2/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.5207 - loss: 1.2314 - val_accuracy: 0.5148 - val_loss: 0.9434 - learning_rate: 3.0000e-04\nEpoch 3/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.5131 - loss: 1.0788 - val_accuracy: 0.5000 - val_loss: 0.9444 - learning_rate: 3.0000e-04\nEpoch 4/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.5068 - loss: 1.0269 - val_accuracy: 0.4313 - val_loss: 0.9352 - learning_rate: 3.0000e-04\nEpoch 5/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.5034 - loss: 0.9796 - val_accuracy: 0.5047 - val_loss: 0.9267 - learning_rate: 3.0000e-04\nEpoch 6/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.4983 - loss: 0.9538 - val_accuracy: 0.5000 - val_loss: 0.9221 - learning_rate: 3.0000e-04\nEpoch 7/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.4976 - loss: 0.9361 - val_accuracy: 0.5000 - val_loss: 0.9144 - learning_rate: 3.0000e-04\nEpoch 8/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.4853 - loss: 0.9226 - val_accuracy: 0.5000 - val_loss: 0.9065 - learning_rate: 3.0000e-04\nEpoch 9/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.5042 - loss: 0.9072 - val_accuracy: 0.5000 - val_loss: 0.8970 - learning_rate: 3.0000e-04\nEpoch 10/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.4999 - loss: 0.8977 - val_accuracy: 0.5000 - val_loss: 0.8867 - learning_rate: 3.0000e-04\nEpoch 11/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.4833 - loss: 0.8867 - val_accuracy: 0.5000 - val_loss: 0.8753 - learning_rate: 3.0000e-04\nEpoch 12/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.5140 - loss: 0.8709 - val_accuracy: 0.5000 - val_loss: 0.8635 - learning_rate: 3.0000e-04\nEpoch 13/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.4889 - loss: 0.8631 - val_accuracy: 0.5000 - val_loss: 0.8512 - learning_rate: 3.0000e-04\nEpoch 14/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.4941 - loss: 0.8494 - val_accuracy: 0.5000 - val_loss: 0.8374 - learning_rate: 3.0000e-04\nEpoch 15/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.4945 - loss: 0.8349 - val_accuracy: 0.5219 - val_loss: 0.8234 - learning_rate: 3.0000e-04\nEpoch 16/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.5018 - loss: 0.8214 - val_accuracy: 0.5000 - val_loss: 0.8105 - learning_rate: 3.0000e-04\nEpoch 17/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.5142 - loss: 0.8087 - val_accuracy: 0.5273 - val_loss: 0.7963 - learning_rate: 3.0000e-04\nEpoch 18/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.5383 - loss: 0.7957 - val_accuracy: 0.5813 - val_loss: 0.7721 - learning_rate: 3.0000e-04\nEpoch 19/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.5547 - loss: 0.7818 - val_accuracy: 0.6469 - val_loss: 0.7342 - learning_rate: 3.0000e-04\nEpoch 20/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.6294 - loss: 0.7481 - val_accuracy: 0.6859 - val_loss: 0.6846 - learning_rate: 3.0000e-04\nEpoch 21/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.6739 - loss: 0.7096 - val_accuracy: 0.7070 - val_loss: 0.6633 - learning_rate: 3.0000e-04\nEpoch 22/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.6740 - loss: 0.7063 - val_accuracy: 0.6516 - val_loss: 0.8663 - learning_rate: 3.0000e-04\nEpoch 23/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.6932 - loss: 0.6891 - val_accuracy: 0.7164 - val_loss: 0.6286 - learning_rate: 3.0000e-04\nEpoch 24/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 191ms/step - accuracy: 0.6941 - loss: 0.6671 - val_accuracy: 0.6781 - val_loss: 0.6716 - learning_rate: 3.0000e-04\nEpoch 25/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.6965 - loss: 0.6732 - val_accuracy: 0.6836 - val_loss: 0.6567 - learning_rate: 3.0000e-04\nEpoch 26/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.6944 - loss: 0.6694 - val_accuracy: 0.6727 - val_loss: 0.6508 - learning_rate: 3.0000e-04\nEpoch 27/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.7019 - loss: 0.6582 - val_accuracy: 0.7211 - val_loss: 0.6231 - learning_rate: 3.0000e-04\nEpoch 28/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.6985 - loss: 0.6519 - val_accuracy: 0.7289 - val_loss: 0.6108 - learning_rate: 3.0000e-04\nEpoch 29/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 196ms/step - accuracy: 0.7062 - loss: 0.6553 - val_accuracy: 0.7102 - val_loss: 0.6178 - learning_rate: 3.0000e-04\nEpoch 30/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 194ms/step - accuracy: 0.6917 - loss: 0.6583 - val_accuracy: 0.5781 - val_loss: 0.7426 - learning_rate: 3.0000e-04\nEpoch 31/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7067 - loss: 0.6497 - val_accuracy: 0.6367 - val_loss: 0.6910 - learning_rate: 3.0000e-04\nEpoch 32/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.6956 - loss: 0.6441 - val_accuracy: 0.7328 - val_loss: 0.6051 - learning_rate: 3.0000e-04\nEpoch 33/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.7042 - loss: 0.6481 - val_accuracy: 0.7391 - val_loss: 0.5889 - learning_rate: 3.0000e-04\nEpoch 34/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7129 - loss: 0.6295 - val_accuracy: 0.7039 - val_loss: 0.6095 - learning_rate: 3.0000e-04\nEpoch 35/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.6916 - loss: 0.6418 - val_accuracy: 0.7391 - val_loss: 0.5905 - learning_rate: 3.0000e-04\nEpoch 36/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.7124 - loss: 0.6284 - val_accuracy: 0.7188 - val_loss: 0.5980 - learning_rate: 3.0000e-04\nEpoch 37/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7096 - loss: 0.6257 - val_accuracy: 0.7414 - val_loss: 0.5759 - learning_rate: 3.0000e-04\nEpoch 38/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 196ms/step - accuracy: 0.6932 - loss: 0.6247 - val_accuracy: 0.7227 - val_loss: 0.6628 - learning_rate: 3.0000e-04\nEpoch 39/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.7188 - loss: 0.6208 - val_accuracy: 0.7297 - val_loss: 0.5947 - learning_rate: 3.0000e-04\nEpoch 40/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.7017 - loss: 0.6163 - val_accuracy: 0.6039 - val_loss: 0.7168 - learning_rate: 3.0000e-04\nEpoch 41/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.7168 - loss: 0.6137 - val_accuracy: 0.5008 - val_loss: 0.8687 - learning_rate: 3.0000e-04\nEpoch 42/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.7081 - loss: 0.6410 - val_accuracy: 0.7148 - val_loss: 0.5923 - learning_rate: 3.0000e-04\nEpoch 43/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.7105 - loss: 0.6146 - val_accuracy: 0.6984 - val_loss: 0.7586 - learning_rate: 3.0000e-04\nEpoch 44/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.7173 - loss: 0.6094 - val_accuracy: 0.7367 - val_loss: 0.5798 - learning_rate: 3.0000e-04\nEpoch 45/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.7154 - loss: 0.6176 - val_accuracy: 0.6750 - val_loss: 0.6305 - learning_rate: 3.0000e-04\nEpoch 46/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 199ms/step - accuracy: 0.7118 - loss: 0.6144 - val_accuracy: 0.6898 - val_loss: 0.6098 - learning_rate: 3.0000e-04\nEpoch 47/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.7190 - loss: 0.6027\nEpoch 47: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 199ms/step - accuracy: 0.7190 - loss: 0.6027 - val_accuracy: 0.7445 - val_loss: 0.5814 - learning_rate: 3.0000e-04\nEpoch 48/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.7381 - loss: 0.5928 - val_accuracy: 0.6891 - val_loss: 0.6266 - learning_rate: 1.5000e-04\nEpoch 49/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.7245 - loss: 0.5965 - val_accuracy: 0.7383 - val_loss: 0.5717 - learning_rate: 1.5000e-04\nEpoch 50/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 199ms/step - accuracy: 0.7386 - loss: 0.5859 - val_accuracy: 0.6250 - val_loss: 0.6755 - learning_rate: 1.5000e-04\nEpoch 51/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7350 - loss: 0.5833 - val_accuracy: 0.6789 - val_loss: 0.6728 - learning_rate: 1.5000e-04\nEpoch 52/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7358 - loss: 0.5847 - val_accuracy: 0.7461 - val_loss: 0.5563 - learning_rate: 1.5000e-04\nEpoch 53/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7422 - loss: 0.5792 - val_accuracy: 0.7719 - val_loss: 0.5287 - learning_rate: 1.5000e-04\nEpoch 54/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 196ms/step - accuracy: 0.7489 - loss: 0.5756 - val_accuracy: 0.7656 - val_loss: 0.5574 - learning_rate: 1.5000e-04\nEpoch 55/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.7531 - loss: 0.5676 - val_accuracy: 0.7711 - val_loss: 0.5194 - learning_rate: 1.5000e-04\nEpoch 56/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7471 - loss: 0.5651 - val_accuracy: 0.7711 - val_loss: 0.5298 - learning_rate: 1.5000e-04\nEpoch 57/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.7474 - loss: 0.5811 - val_accuracy: 0.7500 - val_loss: 0.5515 - learning_rate: 1.5000e-04\nEpoch 58/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7480 - loss: 0.5651 - val_accuracy: 0.7328 - val_loss: 0.5746 - learning_rate: 1.5000e-04\nEpoch 59/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.7412 - loss: 0.5736 - val_accuracy: 0.7703 - val_loss: 0.5188 - learning_rate: 1.5000e-04\nEpoch 60/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.7488 - loss: 0.5688 - val_accuracy: 0.7844 - val_loss: 0.5180 - learning_rate: 1.5000e-04\nEpoch 61/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 191ms/step - accuracy: 0.7464 - loss: 0.5603 - val_accuracy: 0.7352 - val_loss: 0.5878 - learning_rate: 1.5000e-04\nEpoch 62/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 196ms/step - accuracy: 0.7399 - loss: 0.5614 - val_accuracy: 0.7727 - val_loss: 0.5830 - learning_rate: 1.5000e-04\nEpoch 63/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.7672 - loss: 0.5434 - val_accuracy: 0.7781 - val_loss: 0.5206 - learning_rate: 1.5000e-04\nEpoch 64/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7539 - loss: 0.5501 - val_accuracy: 0.7727 - val_loss: 0.5359 - learning_rate: 1.5000e-04\nEpoch 65/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7434 - loss: 0.5645 - val_accuracy: 0.7633 - val_loss: 0.5496 - learning_rate: 1.5000e-04\nEpoch 66/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7604 - loss: 0.5536 - val_accuracy: 0.7797 - val_loss: 0.5443 - learning_rate: 1.5000e-04\nEpoch 67/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.7640 - loss: 0.5539 - val_accuracy: 0.7836 - val_loss: 0.5113 - learning_rate: 1.5000e-04\nEpoch 68/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 191ms/step - accuracy: 0.7540 - loss: 0.5509 - val_accuracy: 0.7914 - val_loss: 0.5040 - learning_rate: 1.5000e-04\nEpoch 69/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.7850 - loss: 0.5276 - val_accuracy: 0.7852 - val_loss: 0.5082 - learning_rate: 1.5000e-04\nEpoch 70/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7823 - loss: 0.5288 - val_accuracy: 0.7945 - val_loss: 0.4760 - learning_rate: 1.5000e-04\nEpoch 71/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7845 - loss: 0.5123 - val_accuracy: 0.8055 - val_loss: 0.4839 - learning_rate: 1.5000e-04\nEpoch 72/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7792 - loss: 0.5276 - val_accuracy: 0.8000 - val_loss: 0.4922 - learning_rate: 1.5000e-04\nEpoch 73/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.7818 - loss: 0.5190 - val_accuracy: 0.7937 - val_loss: 0.4805 - learning_rate: 1.5000e-04\nEpoch 74/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 191ms/step - accuracy: 0.7814 - loss: 0.5068 - val_accuracy: 0.8055 - val_loss: 0.4562 - learning_rate: 1.5000e-04\nEpoch 75/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.7769 - loss: 0.5183 - val_accuracy: 0.7320 - val_loss: 0.6679 - learning_rate: 1.5000e-04\nEpoch 76/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.7859 - loss: 0.4969 - val_accuracy: 0.6516 - val_loss: 0.7805 - learning_rate: 1.5000e-04\nEpoch 77/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7807 - loss: 0.5146 - val_accuracy: 0.7773 - val_loss: 0.5203 - learning_rate: 1.5000e-04\nEpoch 78/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.7846 - loss: 0.5069 - val_accuracy: 0.7937 - val_loss: 0.4973 - learning_rate: 1.5000e-04\nEpoch 79/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.7977 - loss: 0.4825 - val_accuracy: 0.7977 - val_loss: 0.4787 - learning_rate: 1.5000e-04\nEpoch 80/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.7842 - loss: 0.5094 - val_accuracy: 0.7930 - val_loss: 0.4834 - learning_rate: 1.5000e-04\nEpoch 81/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.7901 - loss: 0.4959 - val_accuracy: 0.8109 - val_loss: 0.4759 - learning_rate: 1.5000e-04\nEpoch 82/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.7897 - loss: 0.4952 - val_accuracy: 0.8039 - val_loss: 0.5212 - learning_rate: 1.5000e-04\nEpoch 83/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 191ms/step - accuracy: 0.8044 - loss: 0.4819 - val_accuracy: 0.8219 - val_loss: 0.4572 - learning_rate: 1.5000e-04\nEpoch 84/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.7988 - loss: 0.4927\nEpoch 84: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.7988 - loss: 0.4927 - val_accuracy: 0.8078 - val_loss: 0.4943 - learning_rate: 1.5000e-04\nEpoch 85/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8010 - loss: 0.4857 - val_accuracy: 0.8305 - val_loss: 0.4099 - learning_rate: 7.5000e-05\nEpoch 86/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8159 - loss: 0.4806 - val_accuracy: 0.8367 - val_loss: 0.4383 - learning_rate: 7.5000e-05\nEpoch 87/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8053 - loss: 0.4852 - val_accuracy: 0.8195 - val_loss: 0.4348 - learning_rate: 7.5000e-05\nEpoch 88/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8229 - loss: 0.4534 - val_accuracy: 0.8500 - val_loss: 0.3913 - learning_rate: 7.5000e-05\nEpoch 89/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.8361 - loss: 0.4289 - val_accuracy: 0.8227 - val_loss: 0.4616 - learning_rate: 7.5000e-05\nEpoch 90/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 196ms/step - accuracy: 0.8261 - loss: 0.4434 - val_accuracy: 0.7805 - val_loss: 0.5393 - learning_rate: 7.5000e-05\nEpoch 91/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 196ms/step - accuracy: 0.8168 - loss: 0.4670 - val_accuracy: 0.8281 - val_loss: 0.4145 - learning_rate: 7.5000e-05\nEpoch 92/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.8358 - loss: 0.4326 - val_accuracy: 0.8430 - val_loss: 0.4188 - learning_rate: 7.5000e-05\nEpoch 93/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.8362 - loss: 0.4206 - val_accuracy: 0.8422 - val_loss: 0.3922 - learning_rate: 7.5000e-05\nEpoch 94/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8282 - loss: 0.4280 - val_accuracy: 0.8422 - val_loss: 0.3862 - learning_rate: 7.5000e-05\nEpoch 95/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.8340 - loss: 0.4181 - val_accuracy: 0.8469 - val_loss: 0.4135 - learning_rate: 7.5000e-05\nEpoch 96/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8352 - loss: 0.4312 - val_accuracy: 0.8438 - val_loss: 0.4322 - learning_rate: 7.5000e-05\nEpoch 97/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.8509 - loss: 0.4097 - val_accuracy: 0.8383 - val_loss: 0.4166 - learning_rate: 7.5000e-05\nEpoch 98/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8513 - loss: 0.4080 - val_accuracy: 0.8219 - val_loss: 0.4319 - learning_rate: 7.5000e-05\nEpoch 99/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8526 - loss: 0.3962 - val_accuracy: 0.8438 - val_loss: 0.3816 - learning_rate: 7.5000e-05\nEpoch 100/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8345 - loss: 0.4399 - val_accuracy: 0.8195 - val_loss: 0.4578 - learning_rate: 7.5000e-05\nEpoch 101/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8461 - loss: 0.4144 - val_accuracy: 0.8219 - val_loss: 0.4263 - learning_rate: 7.5000e-05\nEpoch 102/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8570 - loss: 0.3905 - val_accuracy: 0.8469 - val_loss: 0.4109 - learning_rate: 7.5000e-05\nEpoch 103/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.8535 - loss: 0.4057 - val_accuracy: 0.8250 - val_loss: 0.4346 - learning_rate: 7.5000e-05\nEpoch 104/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8544 - loss: 0.3951 - val_accuracy: 0.8062 - val_loss: 0.5236 - learning_rate: 7.5000e-05\nEpoch 105/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8440 - loss: 0.4044 - val_accuracy: 0.8062 - val_loss: 0.5950 - learning_rate: 7.5000e-05\nEpoch 106/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 192ms/step - accuracy: 0.8535 - loss: 0.3896 - val_accuracy: 0.8625 - val_loss: 0.3749 - learning_rate: 7.5000e-05\nEpoch 107/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 191ms/step - accuracy: 0.8659 - loss: 0.3757 - val_accuracy: 0.8117 - val_loss: 0.4979 - learning_rate: 7.5000e-05\nEpoch 108/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8623 - loss: 0.3815 - val_accuracy: 0.8773 - val_loss: 0.3494 - learning_rate: 7.5000e-05\nEpoch 109/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8602 - loss: 0.3698 - val_accuracy: 0.8484 - val_loss: 0.4316 - learning_rate: 7.5000e-05\nEpoch 110/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.8637 - loss: 0.3849 - val_accuracy: 0.8766 - val_loss: 0.3367 - learning_rate: 7.5000e-05\nEpoch 111/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.8631 - loss: 0.3734 - val_accuracy: 0.8742 - val_loss: 0.3441 - learning_rate: 7.5000e-05\nEpoch 112/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8724 - loss: 0.3645 - val_accuracy: 0.8484 - val_loss: 0.4018 - learning_rate: 7.5000e-05\nEpoch 113/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8636 - loss: 0.3861 - val_accuracy: 0.8773 - val_loss: 0.3604 - learning_rate: 7.5000e-05\nEpoch 114/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8677 - loss: 0.3753 - val_accuracy: 0.8727 - val_loss: 0.3825 - learning_rate: 7.5000e-05\nEpoch 115/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8691 - loss: 0.3738 - val_accuracy: 0.8555 - val_loss: 0.3904 - learning_rate: 7.5000e-05\nEpoch 116/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8679 - loss: 0.3644 - val_accuracy: 0.8898 - val_loss: 0.3124 - learning_rate: 7.5000e-05\nEpoch 117/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8835 - loss: 0.3565 - val_accuracy: 0.8484 - val_loss: 0.3761 - learning_rate: 7.5000e-05\nEpoch 118/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8789 - loss: 0.3358 - val_accuracy: 0.8719 - val_loss: 0.3578 - learning_rate: 7.5000e-05\nEpoch 119/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.8827 - loss: 0.3439 - val_accuracy: 0.8555 - val_loss: 0.3848 - learning_rate: 7.5000e-05\nEpoch 120/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8786 - loss: 0.3412 - val_accuracy: 0.8297 - val_loss: 0.4579 - learning_rate: 7.5000e-05\nEpoch 121/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8699 - loss: 0.3614 - val_accuracy: 0.8773 - val_loss: 0.3494 - learning_rate: 7.5000e-05\nEpoch 122/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 190ms/step - accuracy: 0.8799 - loss: 0.3568 - val_accuracy: 0.8805 - val_loss: 0.3427 - learning_rate: 7.5000e-05\nEpoch 123/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 191ms/step - accuracy: 0.8817 - loss: 0.3434 - val_accuracy: 0.8641 - val_loss: 0.4081 - learning_rate: 7.5000e-05\nEpoch 124/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8778 - loss: 0.3475 - val_accuracy: 0.8953 - val_loss: 0.3141 - learning_rate: 7.5000e-05\nEpoch 125/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8904 - loss: 0.3410 - val_accuracy: 0.8922 - val_loss: 0.3073 - learning_rate: 7.5000e-05\nEpoch 126/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 190ms/step - accuracy: 0.8917 - loss: 0.3198 - val_accuracy: 0.8547 - val_loss: 0.3966 - learning_rate: 7.5000e-05\nEpoch 127/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 188ms/step - accuracy: 0.8919 - loss: 0.3225 - val_accuracy: 0.8844 - val_loss: 0.3270 - learning_rate: 7.5000e-05\nEpoch 128/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8922 - loss: 0.3241 - val_accuracy: 0.8984 - val_loss: 0.3035 - learning_rate: 7.5000e-05\nEpoch 129/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8883 - loss: 0.3315 - val_accuracy: 0.8664 - val_loss: 0.3830 - learning_rate: 7.5000e-05\nEpoch 130/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 188ms/step - accuracy: 0.8811 - loss: 0.3285 - val_accuracy: 0.8813 - val_loss: 0.3356 - learning_rate: 7.5000e-05\nEpoch 131/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 188ms/step - accuracy: 0.8962 - loss: 0.3328 - val_accuracy: 0.9109 - val_loss: 0.2531 - learning_rate: 7.5000e-05\nEpoch 132/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 191ms/step - accuracy: 0.8889 - loss: 0.3384 - val_accuracy: 0.9117 - val_loss: 0.2725 - learning_rate: 7.5000e-05\nEpoch 133/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8908 - loss: 0.3509 - val_accuracy: 0.9133 - val_loss: 0.2721 - learning_rate: 7.5000e-05\nEpoch 134/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 191ms/step - accuracy: 0.8977 - loss: 0.3167 - val_accuracy: 0.9141 - val_loss: 0.2777 - learning_rate: 7.5000e-05\nEpoch 135/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8947 - loss: 0.3335 - val_accuracy: 0.9086 - val_loss: 0.2829 - learning_rate: 7.5000e-05\nEpoch 136/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 189ms/step - accuracy: 0.8910 - loss: 0.3010 - val_accuracy: 0.9070 - val_loss: 0.2555 - learning_rate: 7.5000e-05\nEpoch 137/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.8943 - loss: 0.3105 - val_accuracy: 0.8938 - val_loss: 0.3049 - learning_rate: 7.5000e-05\nEpoch 138/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8981 - loss: 0.3052 - val_accuracy: 0.9234 - val_loss: 0.2565 - learning_rate: 7.5000e-05\nEpoch 139/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8982 - loss: 0.3214 - val_accuracy: 0.8953 - val_loss: 0.2882 - learning_rate: 7.5000e-05\nEpoch 140/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.9034 - loss: 0.2945 - val_accuracy: 0.8852 - val_loss: 0.2998 - learning_rate: 7.5000e-05\nEpoch 141/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8997 - loss: 0.3011\nEpoch 141: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 194ms/step - accuracy: 0.8997 - loss: 0.3011 - val_accuracy: 0.8914 - val_loss: 0.2926 - learning_rate: 7.5000e-05\nEpoch 142/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 193ms/step - accuracy: 0.9076 - loss: 0.2889 - val_accuracy: 0.9109 - val_loss: 0.2432 - learning_rate: 3.7500e-05\nEpoch 143/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 195ms/step - accuracy: 0.9119 - loss: 0.2887 - val_accuracy: 0.9156 - val_loss: 0.2571 - learning_rate: 3.7500e-05\nEpoch 144/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 198ms/step - accuracy: 0.9146 - loss: 0.2730 - val_accuracy: 0.8992 - val_loss: 0.2636 - learning_rate: 3.7500e-05\nEpoch 145/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 197ms/step - accuracy: 0.9138 - loss: 0.2768 - val_accuracy: 0.9086 - val_loss: 0.2687 - learning_rate: 3.7500e-05\nEpoch 146/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.9260 - loss: 0.2625 - val_accuracy: 0.9062 - val_loss: 0.2840 - learning_rate: 3.7500e-05\nEpoch 147/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.9190 - loss: 0.2953 - val_accuracy: 0.9094 - val_loss: 0.2464 - learning_rate: 3.7500e-05\nEpoch 148/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.9148 - loss: 0.2713 - val_accuracy: 0.9008 - val_loss: 0.2838 - learning_rate: 3.7500e-05\nEpoch 149/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 198ms/step - accuracy: 0.9101 - loss: 0.2809 - val_accuracy: 0.8844 - val_loss: 0.3349 - learning_rate: 3.7500e-05\nEpoch 150/150\n\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 196ms/step - accuracy: 0.9139 - loss: 0.2828 - val_accuracy: 0.8984 - val_loss: 0.2882 - learning_rate: 3.7500e-05\nRestoring model weights from the end of the best epoch: 138.\n\n Training complete!\n   Time: 310.15 minutes\n","output_type":"stream"}],"execution_count":6},{"id":"c122855b","cell_type":"code","source":"# Evaluation helpers\n\ndef calculate_metrics(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred) * 100,\n        'precision': precision_score(y_true, y_pred, zero_division=0),\n        'recall': recall_score(y_true, y_pred, zero_division=0),\n        'f1_score': f1_score(y_true, y_pred, zero_division=0),\n        'specificity': tn / (tn + fp) if (tn + fp) else 0,\n        'cm': cm\n    }\n    return metrics\n\n# Predict and report\nval_gen.reset()\npred_probs = model.predict(val_gen, verbose=1)\npred_classes = np.argmax(pred_probs, axis=1)\ntrue_classes = val_gen.classes\nmetrics = calculate_metrics(true_classes, pred_classes)\n\nprint(\"Metrics (%):\", {k: round(v, 2) if k=='accuracy' else v for k, v in metrics.items() if k!='cm'})\nprint(\"Confusion matrix:\\n\", metrics['cm'])\nprint(\"\\nClassification report:\\n\", classification_report(true_classes, pred_classes, target_names=['NonDemented','Demented']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:24:06.327708Z","iopub.execute_input":"2025-12-10T17:24:06.327936Z","iopub.status.idle":"2025-12-10T17:24:13.671318Z","shell.execute_reply.started":"2025-12-10T17:24:06.327917Z","shell.execute_reply":"2025-12-10T17:24:13.670637Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step\nMetrics (%): {'accuracy': 92.34, 'precision': 0.9385113268608414, 'recall': 0.90625, 'f1_score': 0.9220985691573926, 'specificity': 0.940625}\nConfusion matrix:\n [[602  38]\n [ 60 580]]\n\nClassification report:\n               precision    recall  f1-score   support\n\n NonDemented       0.91      0.94      0.92       640\n    Demented       0.94      0.91      0.92       640\n\n    accuracy                           0.92      1280\n   macro avg       0.92      0.92      0.92      1280\nweighted avg       0.92      0.92      0.92      1280\n\n","output_type":"stream"}],"execution_count":7},{"id":"2bcf0edb","cell_type":"code","source":"# IEEE-style visualizations (high-res, Times New Roman)\nfrom sklearn.metrics import roc_curve, auc\n\nplt.rcParams.update({\n    'font.family': 'serif',\n    'font.serif': ['Times New Roman'],\n    'font.size': 10,\n    'figure.dpi': 300,\n    'axes.labelsize': 10,\n    'axes.titlesize': 11,\n})\n\nos.makedirs('outputs', exist_ok=True)\n\n# ROC curve\nfpr, tpr, _ = roc_curve(true_classes, pred_probs[:, 1])\nroc_auc = auc(fpr, tpr)\nplt.figure(figsize=(4, 4))\nplt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}', color='navy')\nplt.plot([0, 1], [0, 1], 'k--', linewidth=1)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve (CNN-LSTM)')\nplt.legend(loc='lower right')\nplt.tight_layout()\nplt.savefig('outputs/IEEE_CNN_LSTM_ROC.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n# Confusion matrix (IEEE layout)\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\nplt.figure(figsize=(4, 3.5))\nsns.heatmap(cm_norm, annot=cm, fmt='d', cmap='Blues',\n            xticklabels=['NonDemented', 'Demented'],\n            yticklabels=['NonDemented', 'Demented'],\n            cbar_kws={'label': 'Proportion'})\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix (CNN-LSTM)')\nplt.tight_layout()\nplt.savefig('outputs/IEEE_CNN_LSTM_Confusion.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n# Training curves (IEEE layout)\nplt.figure(figsize=(6, 2.5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train')\nplt.plot(history.history['val_accuracy'], label='Val')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train')\nplt.plot(history.history['val_loss'], label='Val')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss')\nplt.legend()\nplt.tight_layout()\nplt.savefig('outputs/IEEE_CNN_LSTM_Training.png', dpi=300, bbox_inches='tight')\nplt.close()\n\nprint(\"Saved IEEE-ready figures to outputs/ (ROC, confusion, training curves).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:24:13.672103Z","iopub.execute_input":"2025-12-10T17:24:13.672405Z","iopub.status.idle":"2025-12-10T17:24:14.341124Z","shell.execute_reply.started":"2025-12-10T17:24:13.672376Z","shell.execute_reply":"2025-12-10T17:24:14.340278Z"}},"outputs":[{"name":"stderr","text":"findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\nfindfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/2664652400.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Confusion matrix (IEEE layout)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mcm_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m sns.heatmap(cm_norm, annot=cm, fmt='d', cmap='Blues',\n","\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"],"ename":"NameError","evalue":"name 'cm' is not defined","output_type":"error"}],"execution_count":8},{"id":"181751d5","cell_type":"code","source":"# Save model and plots\n\nos.makedirs('outputs', exist_ok=True)\nmodel.save('outputs/CNN_LSTM_Realistic_Aug.h5')\n\n# Training curves\nplt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='val')\nplt.title('Accuracy')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='val')\nplt.title('Loss')\nplt.legend()\nplt.tight_layout()\nplt.savefig('outputs/CNN_LSTM_training_history.png', dpi=150)\nplt.show()\n\n# Confusion matrix plot\ncm = metrics['cm']\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NonD','Dem'], yticklabels=['NonD','Dem'])\nplt.title('Confusion Matrix')\nplt.ylabel('True')\nplt.xlabel('Predicted')\nplt.savefig('outputs/CNN_LSTM_confusion_matrix.png', dpi=150)\nplt.show()\n\nprint(\"Saved model and plots to outputs/.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T17:24:14.341589Z","iopub.status.idle":"2025-12-10T17:24:14.341806Z","shell.execute_reply.started":"2025-12-10T17:24:14.341703Z","shell.execute_reply":"2025-12-10T17:24:14.341713Z"}},"outputs":[],"execution_count":null}]}